"""
config.py

Configuraci√≥n centralizada de la aplicaci√≥n CVFlix con sistema de logging
profesional, validaci√≥n de modelos, ajuste adaptativo de par√°metros y
optimizaciones espec√≠ficas para diferentes entornos de despliegue.

Author: C√©sar S√°nchez Montes
Course: Imagen Digital
Year: 2025
Version: 4.0.0

Architecture:
    Sistema de configuraci√≥n modular organizado en componentes:

    Logging:
        - JSONFormatter: logs estructurados para an√°lisis automatizado
        - ColoredConsoleFormatter: output legible con c√≥digos ANSI
        - RotatingFileHandler: rotaci√≥n autom√°tica de archivos de log

    Validaci√≥n:
        - ModelValidator: verificaci√≥n de modelos de IA al inicio
        - Reportes de modelos faltantes con rutas espec√≠ficas

    Procesamiento:
        - ProcessingConfig: configuraci√≥n adaptativa por duraci√≥n de video
        - Perfiles autom√°ticos (quality/balanced/speed)
        - Estimaci√≥n de tiempos de procesamiento

    Optimizaci√≥n:
        - Detecci√≥n autom√°tica de entorno Render
        - Ajuste de memoria y workers para l√≠mites de RAM
        - Configuraci√≥n espec√≠fica de TensorFlow

Configuration Profiles:
    Quality (videos <2min):
        - face_detection_skip: 10 frames
        - max_frame_width: 960px
        - jpeg_quality: 60
        - M√°ximo detalle, velocidad secundaria

    Balanced (videos 2-10min):
        - face_detection_skip: 15 frames
        - max_frame_width: 720px
        - jpeg_quality: 50
        - Balance entre calidad y velocidad

    Speed (videos >10min):
        - face_detection_skip: 20 frames
        - max_frame_width: 640px
        - jpeg_quality: 45
        - Prioridad en velocidad de procesamiento

Environment Detection:
    Render Platform:
        - Detectado via variable RENDER
        - Workers reducidos a 2 (vs 6 default)
        - Frame width m√°ximo 640px (vs 720px)
        - Skips aumentados para reducir carga
        - Logs de TensorFlow minimizados

Notes:
    El sistema de logging configura autom√°ticamente tres handlers:
        1. JSON rotativo para procesamiento automatizado
        2. Texto rotativo para lectura humana
        3. Consola con colores para desarrollo

    Los archivos de log rotan autom√°ticamente al alcanzar 10MB, manteniendo
    5 backups para JSON y 3 para texto plano.

    La configuraci√≥n se valida al importar el m√≥dulo, registrando estado
    de modelos y directorios en logs. Modelos faltantes no impiden inicio
    pero limitan funcionalidades disponibles.

    En entorno Render (512MB RAM), los workers se reducen autom√°ticamente
    de 6 a 2 y los skips aumentan para prevenir out-of-memory errors.
"""

import os
import logging
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass
import sys
import json
from datetime import datetime

# ==================== CONFIGURACI√ìN PARA SERVIDORES SIN GUI ====================
import matplotlib
matplotlib.use('Agg')  # Backend sin GUI para servidores como Render

# ==================== DIRECTORIOS ====================
BASE_DIR = Path(__file__).resolve().parent.parent
VIDEOS_DIR = BASE_DIR / "videos"
MODEL_DIR = BASE_DIR / "models"
LOGS_DIR = BASE_DIR / "logs"

# Crear directorios necesarios
for directory in [VIDEOS_DIR, MODEL_DIR, LOGS_DIR]:
    directory.mkdir(exist_ok=True)

# ==================== LOGGING PROFESIONAL ====================

class JSONFormatter(logging.Formatter):
    """
    Formateador JSON para logs estructurados procesables autom√°ticamente.

    Genera logs en formato JSON con timestamp UTC, nivel, m√≥dulo, funci√≥n
    y contexto adicional. √ötil para agregaci√≥n en sistemas como ELK,
    Splunk o CloudWatch.

    Notes:
        Los timestamps se formatean en ISO 8601 con zona UTC expl√≠cita.
        Excepciones se incluyen con traceback completo en campo "exception".
        Atributos extra se pueden a√±adir v√≠a record.extra_data.
    """

    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }

        # A√±adir contexto extra si existe
        if hasattr(record, 'extra_data'):
            log_data.update(record.extra_data)

        # A√±adir excepci√≥n si existe
        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)

        return json.dumps(log_data, ensure_ascii=False)


class ColoredConsoleFormatter(logging.Formatter):
    """
    Formateador con c√≥digos de color ANSI para output de consola legible.

    Coloriza nivel de log para identificaci√≥n visual r√°pida durante desarrollo
    y debugging. Los colores se aplican solo al nivel, no al mensaje completo.

    Notes:
        Los c√≥digos ANSI funcionan en terminales Unix/Linux y Windows 10+.
        En entornos sin soporte ANSI, los c√≥digos se muestran como texto.
    """

    # C√≥digos de color ANSI
    COLORS = {
        'DEBUG': '\033[36m',      # Cyan
        'INFO': '\033[32m',       # Green
        'WARNING': '\033[33m',    # Yellow
        'ERROR': '\033[31m',      # Red
        'CRITICAL': '\033[35m',   # Magenta
        'RESET': '\033[0m'        # Reset
    }

    def format(self, record):
        color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        record.levelname = f"{color}{record.levelname}{self.COLORS['RESET']}"
        return super().format(record)


def setup_logging():
    """
    Configura sistema de logging tri-modal de la aplicaci√≥n.

    Crea tres handlers con diferentes prop√≥sitos:
        1. JSON rotativo: para procesamiento automatizado y an√°lisis
        2. Texto rotativo: para lectura humana y debugging
        3. Consola coloreada: para desarrollo y monitoreo en tiempo real

    Notes:
        Los handlers JSON y texto rotan al alcanzar 10MB. JSON mantiene
        5 backups, texto mantiene 3. La consola muestra solo INFO+ para
        evitar spam en desarrollo.

        Loggers de librer√≠as ruidosas (urllib3, matplotlib, PIL) se
        silencian a WARNING para reducir ruido.
    """

    # Handler para archivo JSON (rotativo)
    json_handler = RotatingFileHandler(
        LOGS_DIR / 'cvflix.json.log',
        maxBytes=10 * 1024 * 1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    json_handler.setLevel(logging.INFO)
    json_handler.setFormatter(JSONFormatter())

    # Handler para archivo de texto legible
    text_handler = RotatingFileHandler(
        LOGS_DIR / 'cvflix.log',
        maxBytes=10 * 1024 * 1024,  # 10MB
        backupCount=3,
        encoding='utf-8'
    )
    text_handler.setLevel(logging.INFO)
    text_handler.setFormatter(logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    ))

    # Handler para consola con colores
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(ColoredConsoleFormatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%H:%M:%S'
    ))

    # Configurar logger ra√≠z
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(json_handler)
    root_logger.addHandler(text_handler)
    root_logger.addHandler(console_handler)

    # Silenciar loggers ruidosos
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('matplotlib').setLevel(logging.WARNING)
    logging.getLogger('PIL').setLevel(logging.WARNING)


# Inicializar logging
setup_logging()
logger = logging.getLogger(__name__)

# ==================== MODELOS ====================
FACE_DETECTION_PROTOTXT = MODEL_DIR / "deploy.prototxt"
FACE_DETECTION_WEIGHTS = MODEL_DIR / "res10_300x300_ssd_iter_140000.caffemodel"
EMOTION_MODEL_PATH = MODEL_DIR / "emotion_model.h5"


class ModelValidator:
    """
    Validador de modelos de IA con verificaci√≥n de existencia y tama√±o.

    Verifica que todos los modelos necesarios est√©n presentes en disco
    y reporta su tama√±o para diagnosticar problemas de descarga incompleta.
    """

    @staticmethod
    def validate_models() -> Dict[str, bool]:
        """
        Valida existencia de todos los modelos necesarios.

        Returns:
            Diccionario mapeando nombre de modelo a flag de existencia.

        Notes:
            Registra en logs el estado de cada modelo con tama√±o en MB.
            √ötil para diagnosticar problemas de inicializaci√≥n al revisar logs.
        """
        models = {
            "face_detection_prototxt": FACE_DETECTION_PROTOTXT,
            "face_detection_weights": FACE_DETECTION_WEIGHTS,
            "emotion_model": EMOTION_MODEL_PATH
        }

        status = {}
        for model_name, model_path in models.items():
            exists = model_path.exists()
            status[model_name] = exists

            if exists:
                size_mb = model_path.stat().st_size / (1024 * 1024)
                logger.info(f"‚úÖ {model_name}: {size_mb:.2f} MB")
            else:
                logger.warning(f"‚ö†Ô∏è {model_name} no encontrado en {model_path}")

        return status

    @staticmethod
    def get_missing_models() -> list:
        """
        Retorna lista de nombres de modelos faltantes.

        Returns:
            Lista de strings con nombres de modelos no encontrados.

        Example:
            >>> missing = ModelValidator.get_missing_models()
            >>> if missing:
            >>>     print(f"Instalar modelos: {', '.join(missing)}")
        """
        status = ModelValidator.validate_models()
        return [name for name, exists in status.items() if not exists]


# ==================== API KEYS ====================
TMDB_API_KEY = os.getenv("TMDB_API_KEY")
TMDB_BASE_URL = "https://api.themoviedb.org/3"
TMDB_IMAGE_BASE = "https://image.tmdb.org/t/p/w500"

if not TMDB_API_KEY:
    logger.error("‚ùå TMDB_API_KEY no configurado correctamente")


# ==================== CONFIGURACI√ìN DE PROCESAMIENTO ====================
@dataclass
class ProcessingSettings:
    """
    Configuraci√≥n de procesamiento de video con par√°metros optimizados.

    Attributes:
        face_detection_skip: Frames a saltar entre detecciones faciales.
        full_analysis_skip: Frames a saltar entre an√°lisis completos.
        progress_update_skip: Frames entre actualizaciones de progreso SSE.
        max_frame_width: Ancho m√°ximo para redimensionamiento.
        jpeg_quality: Calidad de compresi√≥n JPEG [1-100].
        priority: Nivel de prioridad (quality/balanced/speed).
    """
    face_detection_skip: int
    full_analysis_skip: int
    progress_update_skip: int
    max_frame_width: int
    jpeg_quality: int
    priority: str


class ProcessingConfig:
    """
    Configuraci√≥n centralizada y adaptativa de procesamiento de video.

    Proporciona valores por defecto optimizados y m√©todos para ajuste
    din√°mico basado en caracter√≠sticas del video (duraci√≥n, resoluci√≥n).
    """

    # Configuraci√≥n base
    FACE_DETECTION_SKIP = 15
    FULL_ANALYSIS_SKIP = 45
    PROGRESS_UPDATE_SKIP = 5

    # Umbrales de confianza
    FACE_CONFIDENCE_THRESHOLD = 0.60
    FACE_RECOGNITION_THRESHOLD = 0.60
    MIN_FACE_SIZE = 50

    # Optimizaci√≥n de im√°genes
    MAX_FRAME_WIDTH = 720
    JPEG_QUALITY = 50
    RESIZE_INTERPOLATION = "INTER_AREA"

    # Procesamiento paralelo
    MAX_WORKERS = 6
    USE_GPU = True
    BATCH_SIZE = 4

    # Tracking facial
    USE_FACE_TRACKING = True
    TRACKING_THRESHOLD = 50

    @classmethod
    def get_optimal_settings(cls, video_duration: float) -> ProcessingSettings:
        """
        Calcula configuraci√≥n √≥ptima seg√∫n duraci√≥n del video.

        Ajusta par√°metros de muestreo y calidad para balance entre
        velocidad de procesamiento y calidad de an√°lisis.

        Args:
            video_duration: Duraci√≥n del video en segundos.

        Returns:
            ProcessingSettings con par√°metros optimizados.

        Notes:
            Estrategia de perfiles:
                - <2min: quality (an√°lisis denso, m√°ximo detalle)
                - 2-10min: balanced (muestreo moderado)
                - >10min: speed (muestreo agresivo para completar r√°pido)
        """
        if video_duration < 120:  # Videos cortos (< 2 min)
            return ProcessingSettings(
                face_detection_skip=10,
                full_analysis_skip=30,
                progress_update_skip=3,
                max_frame_width=960,
                jpeg_quality=60,
                priority="quality"
            )
        elif video_duration < 600:  # Videos medianos (2-10 min)
            return ProcessingSettings(
                face_detection_skip=cls.FACE_DETECTION_SKIP,
                full_analysis_skip=cls.FULL_ANALYSIS_SKIP,
                progress_update_skip=cls.PROGRESS_UPDATE_SKIP,
                max_frame_width=cls.MAX_FRAME_WIDTH,
                jpeg_quality=cls.JPEG_QUALITY,
                priority="balanced"
            )
        else:  # Videos largos (> 10 min)
            return ProcessingSettings(
                face_detection_skip=20,
                full_analysis_skip=60,
                progress_update_skip=8,
                max_frame_width=640,
                jpeg_quality=45,
                priority="speed"
            )

    @classmethod
    def estimate_processing_time(cls, total_frames: int, fps: float) -> Dict[str, float]:
        """
        Estima tiempo de procesamiento basado en caracter√≠sticas del video.

        Args:
            total_frames: N√∫mero total de frames en el video.
            fps: Frame rate del video.

        Returns:
            Diccionario con estimaciones en segundos y minutos.

        Notes:
            La estimaci√≥n asume 0.3s por frame analizado en hardware t√≠pico.
            Tiempo real var√≠a seg√∫n n√∫mero de rostros, resoluci√≥n y hardware.
        """
        frames_to_analyze = total_frames // cls.FACE_DETECTION_SKIP
        estimated_seconds = frames_to_analyze * 0.3  # 0.3s por frame analizado

        return {
            "total_frames": total_frames,
            "frames_to_analyze": frames_to_analyze,
            "estimated_seconds": round(estimated_seconds, 1),
            "estimated_minutes": round(estimated_seconds / 60, 2),
            "fps": fps
        }


# ==================== CONFIGURACI√ìN DE AN√ÅLISIS ====================
ANALYSIS_CONFIG = {
    "face_detection": {
        "enabled": True,
        "skip_frames": ProcessingConfig.FACE_DETECTION_SKIP,
        "priority": "high",
        "description": "Detecci√≥n de rostros con DNN"
    },
    "face_recognition": {
        "enabled": True,
        "skip_frames": ProcessingConfig.FACE_DETECTION_SKIP,
        "priority": "high",
        "description": "Reconocimiento facial de actores"
    },
    "emotion_detection": {
        "enabled": True,
        "skip_frames": ProcessingConfig.FULL_ANALYSIS_SKIP,
        "priority": "medium",
        "description": "Detecci√≥n de emociones faciales"
    },
    "shot_type": {
        "enabled": True,
        "skip_frames": ProcessingConfig.FULL_ANALYSIS_SKIP,
        "priority": "medium",
        "description": "An√°lisis de tipo de plano"
    },
    "composition": {
        "enabled": True,
        "skip_frames": ProcessingConfig.FULL_ANALYSIS_SKIP * 2,
        "priority": "low",
        "description": "An√°lisis de composici√≥n visual"
    },
    "lighting": {
        "enabled": True,
        "skip_frames": ProcessingConfig.FULL_ANALYSIS_SKIP,
        "priority": "medium",
        "description": "An√°lisis de iluminaci√≥n"
    },
    "colors": {
        "enabled": True,
        "skip_frames": ProcessingConfig.FULL_ANALYSIS_SKIP,
        "priority": "medium",
        "description": "An√°lisis de paleta de colores"
    },
    "camera_movement": {
        "enabled": True,
        "skip_frames": 10,
        "priority": "high",
        "description": "Detecci√≥n de movimientos de c√°mara"
    }
}


# ==================== CONFIGURACI√ìN DE EMOCIONES ====================
EMOTION_CONFIG = {
    "model_type": "keras",
    "input_size": (48, 48),
    "labels": ['Enfadado', 'Disgustado', 'Miedo', 'Feliz', 'Neutral', 'Triste', 'Sorprendido'],
    "enabled": EMOTION_MODEL_PATH.exists()
}


# ==================== CORS ====================
CORS_ORIGINS = ["*"]


# ==================== RATE LIMITING ====================
RATE_LIMIT_CONFIG = {
    "upload_video": "5/minute",  # 5 uploads por minuto
    "search_content": "30/minute",  # 30 b√∫squedas por minuto
}


# ==================== CONSTANTES EXPORTADAS ====================
# Exportar para compatibilidad con c√≥digo existente
FACE_DETECTION_SKIP = ProcessingConfig.FACE_DETECTION_SKIP
FULL_ANALYSIS_SKIP = ProcessingConfig.FULL_ANALYSIS_SKIP
PROGRESS_UPDATE_SKIP = ProcessingConfig.PROGRESS_UPDATE_SKIP
FACE_CONFIDENCE_THRESHOLD = ProcessingConfig.FACE_CONFIDENCE_THRESHOLD
FACE_RECOGNITION_THRESHOLD = ProcessingConfig.FACE_RECOGNITION_THRESHOLD
MIN_FACE_SIZE = ProcessingConfig.MIN_FACE_SIZE
MAX_FRAME_WIDTH = ProcessingConfig.MAX_FRAME_WIDTH
JPEG_QUALITY = ProcessingConfig.JPEG_QUALITY
MAX_WORKERS = ProcessingConfig.MAX_WORKERS
USE_FACE_TRACKING = ProcessingConfig.USE_FACE_TRACKING
TRACKING_THRESHOLD = ProcessingConfig.TRACKING_THRESHOLD


# ==================== VALIDACI√ìN AL IMPORTAR ====================
logger.info("=" * 70)
logger.info("üîß CVFlix Backend v4.0.0 - Validando configuraci√≥n...")
logger.info("=" * 70)

models_status = ModelValidator.validate_models()
missing = ModelValidator.get_missing_models()

if missing:
    logger.warning(f"‚ö†Ô∏è Modelos faltantes: {', '.join(missing)}")
    logger.warning("   Algunas funcionalidades estar√°n limitadas")
else:
    logger.info("‚úÖ Todos los modelos disponibles")

logger.info(f"üìÅ BASE_DIR: {BASE_DIR}")
logger.info(f"üìπ VIDEOS_DIR: {VIDEOS_DIR}")
logger.info(f"ü§ñ MODEL_DIR: {MODEL_DIR}")
logger.info(f"üìä LOGS_DIR: {LOGS_DIR}")
logger.info("=" * 70)

# ==================== CONFIGURACI√ìN ESPEC√çFICA PARA RENDER ====================
IS_RENDER = os.getenv('RENDER') is not None

if IS_RENDER:
    logger.info("üöÄ Modo RENDER detectado - Aplicando optimizaciones...")

    # Reducir uso de memoria para Render (512MB RAM)
    ProcessingConfig.MAX_WORKERS = 2  # Reducido de 6 a 2
    ProcessingConfig.MAX_FRAME_WIDTH = 640  # Reducido de 720 a 640
    ProcessingConfig.FACE_DETECTION_SKIP = 20  # Analizar menos frames
    ProcessingConfig.FULL_ANALYSIS_SKIP = 60  # Analizar menos frames
    ProcessingConfig.PROGRESS_UPDATE_SKIP = 10  # Actualizar menos frecuentemente

    # Configuraci√≥n de TensorFlow para Render
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reducir logs de TF
    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'

    logger.info("‚úÖ Optimizaciones de Render aplicadas")
    logger.info(f"   - Workers: {ProcessingConfig.MAX_WORKERS}")
    logger.info(f"   - Max frame width: {ProcessingConfig.MAX_FRAME_WIDTH}")
    logger.info(f"   - Face detection skip: {ProcessingConfig.FACE_DETECTION_SKIP}")